import requests
from bs4 import BeautifulSoup
import sys

# The URL of the news website we want to scrape
URL = "https://news.ycombinator.com/"

try:
    # --- 1. Use requests to fetch HTML ---
    # We add a user-agent header to identify our script, which is good practice.
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
    response = requests.get(URL, headers=headers)
    
    # Raise an exception if the request was unsuccessful (e.g., 404, 500)
    response.raise_for_status()

    # --- 2. Use BeautifulSoup to parse tags ---
    soup = BeautifulSoup(response.text, 'html.parser')

    # Inspecting Hacker News, all story headlines are in a <span>
    # with the class "titleline". We find all of them.
    headline_spans = soup.find_all('span', class_='titleline')

    if not headline_spans:
        print("No headlines found. The website structure may have changed.")
        sys.exit(1)

    headlines_list = []
    for span in headline_spans:
        # The text is inside an <a> tag within the <span>
        headline_anchor = span.find('a')
        if headline_anchor:
            # .strip() removes any leading/trailing whitespace
            title = headline_anchor.text.strip()
            headlines_list.append(title)

    # --- 3. Save the titles in a .txt file ---
    with open('headlines.txt', 'w', encoding='utf-8') as f:
        for index, title in enumerate(headlines_list):
            f.write(f"{index + 1}. {title}\n")
    
    print(f"Successfully scraped {len(headlines_list)} headlines.")
    print("Headlines saved to 'headlines.txt'.")

except requests.exceptions.RequestException as e:
    print(f"Error fetching the URL: {e}")
except IOError as e:
    print(f"Error writing to file: {e}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")
